{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZbkAER5o1DXn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "uXOjaIvN3puB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparams\n",
        "\n",
        "num_epochs=5\n",
        "lr=0.001\n",
        "batch_size=4\n",
        "\n"
      ],
      "metadata": {
        "id": "E8N51vhP32vw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformation=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "\n",
        "train_dataset=torchvision.datasets.CIFAR10(root=\"./data\",train=True, download=True,transform=transformation)\n",
        "test_dataset=torchvision.datasets.CIFAR10(root=\"./data\",train=False, download=True,transform=transformation)\n",
        "\n"
      ],
      "metadata": {
        "id": "EOE_odxL4Ag4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=dataloader.DataLoader(train_dataset,batch_size=4,shuffle=False)\n",
        "test_data=dataloader.DataLoader(test_dataset,batch_size=4,shuffle=False)"
      ],
      "metadata": {
        "id": "F_ARL-M-5QmO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "n3YRT1SV5y9N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1=nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5)\n",
        "    self.pool=nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2=nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "    # flatten 3d tensor to 1d tensor that is why 16*5*5\n",
        "    self.fc1=nn.Linear(in_features=16*5*5,out_features=120)\n",
        "    self.fc2=nn.Linear(in_features=120,out_features=84)\n",
        "    self.fc3=nn.Linear(in_features=84,out_features=10)\n",
        "\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self,x):\n",
        "    # -> 3,32,32\n",
        "    x=self.conv1(x) # 6, 28, 28\n",
        "    x=F.relu(x) # 6, 28, 28\n",
        "    x=self.pool(x) # 6, 14, 14\n",
        "    x=self.conv2(x) # 16 , 10, 10\n",
        "    x=F.relu(x) # 16, 10 , 10\n",
        "    x=self.pool(x) # 16, 5, 5\n",
        "    # first flatten\n",
        "    x=x.view(-1,16*5*5) # pytorch defines right size -1 is batch size #400\n",
        "    x=self.fc1(x) # 120\n",
        "    x=F.relu(x) # 120\n",
        "    x=self.fc2(x) #84\n",
        "    x=F.relu(x) # 84\n",
        "    x=self.fc3(x) #10\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "nJQnqxUI6CeH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model =ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
        "n_total_steps = len(train_dataset)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images,labels) in enumerate(train_data):\n",
        "\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "\n",
        "    #fwd pass\n",
        "\n",
        "    outputs=model(images)\n",
        "    loss=criterion(outputs,labels)\n",
        "\n",
        "    # bwd pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%2000==0:\n",
        "      print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}, Loss: {loss.item():.4f}]\")\n",
        "\n",
        "  print(\"Finished Training.\")\n"
      ],
      "metadata": {
        "id": "D4yTqWWX6bPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08db3c51-bbab-4c81-c00d-b8320d1484ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [2000/50000, Loss: 2.3222]\n",
            "Epoch [1/5], Step [4000/50000, Loss: 2.3422]\n",
            "Epoch [1/5], Step [6000/50000, Loss: 2.3063]\n",
            "Epoch [1/5], Step [8000/50000, Loss: 2.2918]\n",
            "Epoch [1/5], Step [10000/50000, Loss: 2.1214]\n",
            "Epoch [1/5], Step [12000/50000, Loss: 2.2835]\n",
            "Finished Training.\n",
            "Epoch [2/5], Step [2000/50000, Loss: 2.6860]\n",
            "Epoch [2/5], Step [4000/50000, Loss: 2.2951]\n",
            "Epoch [2/5], Step [6000/50000, Loss: 1.5184]\n",
            "Epoch [2/5], Step [8000/50000, Loss: 1.7361]\n",
            "Epoch [2/5], Step [10000/50000, Loss: 2.4663]\n",
            "Epoch [2/5], Step [12000/50000, Loss: 1.5189]\n",
            "Finished Training.\n",
            "Epoch [3/5], Step [2000/50000, Loss: 2.5871]\n",
            "Epoch [3/5], Step [4000/50000, Loss: 2.1803]\n",
            "Epoch [3/5], Step [6000/50000, Loss: 1.6547]\n",
            "Epoch [3/5], Step [8000/50000, Loss: 1.6294]\n",
            "Epoch [3/5], Step [10000/50000, Loss: 2.6447]\n",
            "Epoch [3/5], Step [12000/50000, Loss: 1.1942]\n",
            "Finished Training.\n",
            "Epoch [4/5], Step [2000/50000, Loss: 2.3736]\n",
            "Epoch [4/5], Step [4000/50000, Loss: 2.1694]\n",
            "Epoch [4/5], Step [6000/50000, Loss: 1.9347]\n",
            "Epoch [4/5], Step [8000/50000, Loss: 1.5438]\n",
            "Epoch [4/5], Step [10000/50000, Loss: 2.6119]\n",
            "Epoch [4/5], Step [12000/50000, Loss: 1.0459]\n",
            "Finished Training.\n",
            "Epoch [5/5], Step [2000/50000, Loss: 2.4040]\n",
            "Epoch [5/5], Step [4000/50000, Loss: 2.1881]\n",
            "Epoch [5/5], Step [6000/50000, Loss: 1.8989]\n",
            "Epoch [5/5], Step [8000/50000, Loss: 1.3887]\n",
            "Epoch [5/5], Step [10000/50000, Loss: 2.7136]\n",
            "Epoch [5/5], Step [12000/50000, Loss: 0.8732]\n",
            "Finished Training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_data:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfMJ4E--tO72",
        "outputId": "03aa2021-6f58-4864-9408-a061d056f30b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network: 48.9 %\n",
            "Accuracy of plane: 43.9 %\n",
            "Accuracy of car: 77.3 %\n",
            "Accuracy of bird: 28.7 %\n",
            "Accuracy of cat: 32.3 %\n",
            "Accuracy of deer: 32.3 %\n",
            "Accuracy of dog: 37.3 %\n",
            "Accuracy of frog: 62.3 %\n",
            "Accuracy of horse: 68.7 %\n",
            "Accuracy of ship: 63.5 %\n",
            "Accuracy of truck: 42.7 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5kfc0SN-MxE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}